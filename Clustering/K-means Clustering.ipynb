{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Load MovieLens small dataset\n",
    "ratings_data = pd.read_csv(\"/Users/yushiyang/desktop/RecSys-Materials/ml-latest-small/ratings.csv\")  # Replace with your file path\n",
    "movies_data = pd.read_csv(\"/Users/yushiyang/desktop/RecSys-Materials/ml-latest-small/movies.csv\")  # Replace with your file path\n",
    "\n",
    "# Create a user-movie matrix\n",
    "user_movie_matrix = ratings_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Choose a user for whom you want to find similar users\n",
    "target_user_id = 1  # Change this to the desired user ID\n",
    "\n",
    "# Get the movie ratings vector for the target user\n",
    "target_user_vector = user_movie_matrix.loc[target_user_id].values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means Clustering to find similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yushiyang/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar users to user 1 are: [[  1 325 634 341 310 207  35 485 229 403 539 391 276 290 280 470 604 335\n",
      "   49 477 202 669 545 546 315 320 521 601 167  76 321 618 330 617 424 372\n",
      "  398 360 198 103 436 141 233  54  90 613 404  27 576 511 196 252 661  70\n",
      "  551 614 318 419 326 211 257 395 186 467 507 611 606 337 488 193 222 351\n",
      "  226 154 656 190  25  96 626 482   9 386  98 557 308 579 474  87  81  33\n",
      "  361  79 453 476 414 429 435 411 469 465 454 397 437 438 406 462 443 444\n",
      "  445 459 455 446 448 451 399 464 413 526 489 609 610 612 616 622 625 628\n",
      "  630 631 632 635 636 637 638 640 642 643 644 645 650 651 653 657 663 668\n",
      "  600 484 591 581 490 491 492 493 498 499 503 504 506 512 515 524 538 540\n",
      "  541 543 549 552 554 565 566 567 571 573 578 583 393 334 383 112 113 115\n",
      "  116 117 122 123 127 129 131 132 135 109 140 147 153 156 158 162 166 170\n",
      "  171 172 173 174 179 142 180 107 100   3   6  10  11  12  13  14  16  18\n",
      "   24  28  29 106  37  45  46  51  52  53  55  58  60  62  65  71  80  44\n",
      "  181 183 189 301 305 314 319 322 323 327 329 331 332 336 340 296 343 348\n",
      "  349 356 357 359 364 365 366 368 374 376 377 347 289 286 284 203 204 206\n",
      "  208 209 210 215 218 221 223 227 231 237 238 246 249 256 258 259 260 264\n",
      "  267 269 272 274 277 278 392 670]]\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Means clustering\n",
    "num_clusters = 50  # You can adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_assignments = kmeans.fit_predict(user_movie_matrix)\n",
    "\n",
    "# Find users in the same cluster as the target user\n",
    "target_user_cluster = cluster_assignments[target_user_id - 1]\n",
    "similar_users = np.where(cluster_assignments == target_user_cluster)[0]\n",
    "\n",
    "# Calculate pairwise distances between the target user and similar users\n",
    "pairwise_dist = pairwise_distances(target_user_vector, user_movie_matrix.iloc[similar_users], metric='cosine')\n",
    "\n",
    "# Sort similar users by distance (similarity)\n",
    "sorted_similar_users = similar_users[np.argsort(pairwise_dist)]\n",
    "\n",
    "# Print similar user IDs\n",
    "print(f\"Similar users to user {target_user_id} are: {sorted_similar_users + 1}\")  # Adding 1 to user IDs for display\n",
    "\n",
    "# You can also get the movie recommendations for the target user using the similar users\n",
    "# For example, find the top-rated movie among the similar users\n",
    "# similar_users_ratings = user_movie_matrix.iloc[sorted_similar_users]\n",
    "# top_movie = similar_users_ratings.mean(axis=0).idxmax()\n",
    "# recommended_movie_title = movies_data[movies_data['movieId'] == top_movie]['title'].values[0]\n",
    "# print(f\"Recommended movie for user {target_user_id}: {recommended_movie_title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means Clustering from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MovieLens small dataset\n",
    "ratings_data = pd.read_csv(\"/Users/yushiyang/desktop/RecSys-Materials/ml-latest-small/ratings.csv\")  # Replace with your file path\n",
    "movies_data = pd.read_csv(\"/Users/yushiyang/desktop/RecSys-Materials/ml-latest-small/movies.csv\")  # Replace with your file path\n",
    "\n",
    "# Create a user-movie interaction matrix\n",
    "interaction_matrix = ratings_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Fill missing values with 0 (no interaction)\n",
    "interaction_matrix = interaction_matrix.fillna(0)\n",
    "\n",
    "# Convert the interaction matrix to a numpy array\n",
    "user_item_matrix = interaction_matrix.values\n",
    "\n",
    "# K-Means implementation from scratch\n",
    "def kmeans(data, k, max_iters=100):\n",
    "    n_samples, n_features = data.shape\n",
    "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        # Assign each data point to the nearest centroid\n",
    "        labels = np.argmin(np.linalg.norm(data[:, np.newaxis] - centroids, axis=2), axis=1)\n",
    "\n",
    "        # Update centroids\n",
    "        new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.all(centroids == new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return centroids, labels\n",
    "\n",
    "# Set the number of clusters (K)\n",
    "k = 5\n",
    "\n",
    "# Run K-Means\n",
    "centroids, labels = kmeans(user_item_matrix, k)\n",
    "\n",
    "# Display cluster sizes\n",
    "cluster_sizes = np.bincount(labels)\n",
    "for cluster_id, size in enumerate(cluster_sizes):\n",
    "    print(f\"Cluster {cluster_id}: {size} users\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
