{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSHForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lsh_forest(data, num_permutations, seed):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Compute MinHash signatures\n",
    "    minhash = []\n",
    "    for movie_names in data['title']:\n",
    "        # Ensured the same permutation for all users\n",
    "        m = MinHash(num_perm=num_permutations, seed=seed)\n",
    "        # MinHash all the movie names (shingles) for this user \n",
    "        for movie_name in movie_names:\n",
    "            m.update(movie_name.encode('utf8'))\n",
    "        minhash.append(m)\n",
    "\n",
    "    # Build a forest of all the MinHashed strings\n",
    "    forest = MinHashLSHForest(num_perm=num_permutations)\n",
    " \n",
    "    for i, minmash in enumerate(minhash):\n",
    "        forest.add(i, minmash)\n",
    "\n",
    "    # Index the forest to make it searchable      \n",
    "    forest.index()\n",
    "\n",
    "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(rated_movies, database, num_permutations, seed, num_results, forest):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    m = MinHash(num_perm=num_permutations, seed=seed)\n",
    "    for movie_name in rated_movies:\n",
    "        m.update(movie_name.encode('utf8'))\n",
    "        \n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        print('\\n We couldn not find similar users to your favourite movies. \\n')\n",
    "        return None\n",
    "    \n",
    "    similar_users = database.iloc[idx_array].reset_index(drop=True)[['userId', 'title']]\n",
    "    \n",
    "    print('It took %s seconds to query forest.' % (time.time() - start_time))\n",
    "    \n",
    "    return similar_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId                                              title\n",
      "0         1  [Dangerous Minds (1995), Dumbo (1941), Sleeper...\n",
      "1         2  [GoldenEye (1995), Sense and Sensibility (1995...\n",
      "2         3  [Braveheart (1995), Pulp Fiction (1994), Forre...\n",
      "3         4  [Star Trek: The Motion Picture (1979), French ...\n",
      "4         5  [Antz (1998), Clueless (1995), Apollo 13 (1995...\n",
      "..      ...                                                ...\n",
      "666     667  [Sense and Sensibility (1995), Braveheart (199...\n",
      "667     668  [Pulp Fiction (1994), Silence of the Lambs, Th...\n",
      "668     669  [French Connection, The (1971), Clerks (1994),...\n",
      "669     670  [Seven (a.k.a. Se7en) (1995), Usual Suspects, ...\n",
      "670     671  [Blazing Saddles (1974), Usual Suspects, The (...\n",
      "\n",
      "[671 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasketch import MinHash, MinHashLSHForest\n",
    "\n",
    "# Load ratings data\n",
    "ratings_data = pd.read_csv(\"/Users/yushiyang/desktop/RecSys-Materials/ml-latest-small/ratings.csv\")  # Replace with your file path\n",
    "\n",
    "# Load movies data\n",
    "movies_data = pd.read_csv(\"/Users/yushiyang/desktop/RecSys-Materials/ml-latest-small/movies.csv\")  # Replace with your file path\n",
    "\n",
    "# Merge ratings and movies data to get movie names for each user\n",
    "data = ratings_data.merge(movies_data, on='movieId')\n",
    "\n",
    "# Group movie names by user\n",
    "grouped_data = data.groupby('userId')['title'].apply(list).reset_index()\n",
    "\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations = 256\n",
    "num_recommendations = 10\n",
    "my_seed = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.8607230186462402 seconds to build forest.\n"
     ]
    }
   ],
   "source": [
    "forest = get_lsh_forest(grouped_data, num_permutations, my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.007055997848510742 seconds to query forest.\n",
      "\n",
      " Most similar User(s) are \n",
      "    userId                                              title\n",
      "0     578  [Sense and Sensibility (1995), Usual Suspects,...\n"
     ]
    }
   ],
   "source": [
    "test_user = ['Titanic (1997)'\n",
    "    'Toy Story (1995)',\n",
    "    'Inception (2010)',\n",
    "    'The Hunger Games (2012)',\n",
    "    'Ice Age 4: Continental Drift (2012)',\n",
    "    'Gone Girl (2014)',\n",
    "    'Harry Potter and the Deathly Hallows: Part 1 (2010)',\n",
    "    'Winnie the Pooh (2011)',\n",
    "    'Frozen (2013)']\n",
    "similar_users = predict(test_user, grouped_data, num_permutations, my_seed, num_recommendations, forest)\n",
    "print('\\n Most similar User(s) are \\n', similar_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.00601506233215332 seconds to query forest.\n",
      "\n",
      " Most similar User(s) are \n",
      "    userId                                              title\n",
      "0       1  [Dangerous Minds (1995), Dumbo (1941), Sleeper...\n",
      "1     290  [Dracula (Bram Stoker's Dracula) (1992), Star ...\n",
      "2      35  [Dumbo (1941), Tron (1982), Time Bandits (1981...\n",
      "3     325  [Dangerous Minds (1995), Sleepers (1996), Esca...\n",
      "4       9  [Antz (1998), Sense and Sensibility (1995), Se...\n",
      "5     618  [Dracula (Bram Stoker's Dracula) (1992), Usual...\n",
      "6     207  [Ben-Hur (1959), Dracula (Bram Stoker's Dracul...\n",
      "7     337  [Dracula (Bram Stoker's Dracula) (1992), Termi...\n",
      "8     310  [Dangerous Minds (1995), Dracula (Bram Stoker'...\n",
      "9     634  [Escape from New York (1981), Gandhi (1982), S...\n"
     ]
    }
   ],
   "source": [
    "# Test of validity of returned users by using an existing user as test user\n",
    "first_user = ['Dangerous Minds (1995)', 'Dumbo (1941)', 'Sleepers (1996)', 'Escape from New York (1981)', 'Cinema Paradiso (Nuovo cinema Paradiso) (1989)', 'Deer Hunter, The (1978)', 'Ben-Hur (1959)', 'Gandhi (1982)', \"Dracula (Bram Stoker's Dracula) (1992)\", 'Cape Fear (1991)', 'Star Trek: The Motion Picture (1979)', 'Beavis and Butt-Head Do America (1996)', 'French Connection, The (1971)', 'Tron (1982)', 'Gods Must Be Crazy, The (1980)', 'Willow (1988)', 'Antz (1998)', 'Fly, The (1986)', 'Time Bandits (1981)', 'Blazing Saddles (1974)']\n",
    "similar_users = predict(first_user, grouped_data, num_permutations, my_seed, num_recommendations, forest)\n",
    "print('\\n Most similar User(s) are \\n', similar_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
